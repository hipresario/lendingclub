{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximation I\n",
    "\n",
    "## Linear Functions\n",
    "\n",
    "### Text classification\n",
    "**Twenty Newsgroup Dataset**\n",
    "According to the website http://qwone.com/~jason/20Newsgroups/\n",
    "\n",
    "*The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. To the best of our knowledge, it was originally collected by Ken Lang, probably for his paper “Newsweeder: Learning to filter netnews,” though he does not explicitly mention this collection. The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.*\n",
    "\n",
    "The following example is modified from the Scikit Learn tutorial: http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Select only 4 categories to speed things up\n",
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
    "\n",
    "# Fetch training and test sets\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "                                  categories=categories, shuffle=True, random_state=42)\n",
    "twenty_test = fetch_20newsgroups(subset='test',\n",
    "                                 categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "# Have a look at the first few lines\n",
    "print \"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3])\n",
    "print \"\\n\", twenty_train.target_names[twenty_train.target[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tokenize the documents, get the counts for each word, convert it into TF-IDF representation. Then we run linear and Radial basis function SVM on it. \n",
    "\n",
    "Try various parameters to see if the RBF SVM can outperform the linear SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "\n",
    "# The pipeline tokenizes the documents, convert it into TF-IDF representation before\n",
    "# using the classifier\n",
    "linSVM = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', svm.LinearSVC(loss='hinge', C=10)),])\n",
    "\n",
    "linSVM.fit(twenty_train.data, twenty_train.target)\n",
    "linPredicted = linSVM.predict(twenty_test.data)\n",
    "print \"Linear SVM error: \" + repr(np.mean(linPredicted == twenty_test.target))\n",
    "\n",
    "rbfSVM = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', svm.SVC(kernel='rbf', gamma=0.1, C=10)),])\n",
    "rbfSVM.fit(twenty_train.data, twenty_train.target)\n",
    "rbfPredicted = rbfSVM.predict(twenty_test.data)\n",
    "print \"RBF SVM error: \" + repr(np.mean(rbfPredicted == twenty_test.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Combination of Functions\n",
    "\n",
    "We will run different classifiers on a few datasets. Which ones do you think will do well? Do you need nonlinear functions for these problems?\n",
    "\n",
    "We will first do the digits problem with linear logistic regression, RBF SVM, decision tree and boosted decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at the digits visually\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = load_digits()\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(1, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Cross validation with 10 iterations\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "lr = LogisticRegression(C=0.005, multi_class='multinomial', solver='newton-cg')\n",
    "scores_lr = cross_val_score(lr, digits.data, digits.target, cv=cv)\n",
    "print \"Logistic regression: \" + repr(scores_lr.mean())\n",
    "\n",
    "rbfSVM = svm.SVC(kernel='rbf', gamma=0.001, C=1)\n",
    "scores_rbf = cross_val_score(rbfSVM, digits.data, digits.target, cv=cv)\n",
    "print \"RBF SVM: \" + repr(scores_rbf.mean())\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "scores_dt = cross_val_score(dt, digits.data, digits.target, cv=cv)\n",
    "print \"Decision Tree: \" + repr(scores_dt.mean())\n",
    "\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=10),\n",
    "                         n_estimators=100,random_state=1)\n",
    "scores_bdt = cross_val_score(bdt, digits.data, digits.target, cv=cv)\n",
    "print \"Boosting Decision Trees: \" + repr(scores_bdt.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now consider a credit card approval dataset (from Germany): https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)\n",
    "\n",
    "We will use linear logistic regression, RBF SVM, decision tree and boosted decision trees.\n",
    "\n",
    "The features are:\n",
    "\n",
    "* Attribute 1: (qualitative) \n",
    "Status of existing checking account \n",
    "A11 : ... < 0 DM \n",
    "A12 : 0 <= ... < 200 DM \n",
    "A13 : ... >= 200 DM / salary assignments for at least 1 year \n",
    "A14 : no checking account \n",
    "\n",
    "* Attribute 2: (numerical) \n",
    "Duration in month \n",
    "\n",
    "* Attribute 3: (qualitative) \n",
    "Credit history \n",
    "A30 : no credits taken/ all credits paid back duly \n",
    "A31 : all credits at this bank paid back duly \n",
    "A32 : existing credits paid back duly till now \n",
    "A33 : delay in paying off in the past \n",
    "A34 : critical account/ other credits existing (not at this bank) \n",
    "\n",
    "* Attribute 4: (qualitative) \n",
    "Purpose \n",
    "A40 : car (new) \n",
    "A41 : car (used) \n",
    "A42 : furniture/equipment \n",
    "A43 : radio/television \n",
    "A44 : domestic appliances \n",
    "A45 : repairs \n",
    "A46 : education \n",
    "A47 : (vacation - does not exist?) \n",
    "A48 : retraining \n",
    "A49 : business \n",
    "A410 : others \n",
    "\n",
    "* Attribute 5: (numerical) \n",
    "Credit amount \n",
    "\n",
    "* Attibute 6: (qualitative) \n",
    "Savings account/bonds \n",
    "A61 : ... < 100 DM \n",
    "A62 : 100 <= ... < 500 DM \n",
    "A63 : 500 <= ... < 1000 DM \n",
    "A64 : .. >= 1000 DM \n",
    "A65 : unknown/ no savings account \n",
    "\n",
    "* Attribute 7: (qualitative) \n",
    "Present employment since \n",
    "A71 : unemployed \n",
    "A72 : ... < 1 year \n",
    "A73 : 1 <= ... < 4 years \n",
    "A74 : 4 <= ... < 7 years \n",
    "A75 : .. >= 7 years \n",
    "\n",
    "* Attribute 8: (numerical) \n",
    "Installment rate in percentage of disposable income \n",
    "\n",
    "* Attribute 9: (qualitative) \n",
    "Personal status and sex \n",
    "A91 : male : divorced/separated \n",
    "A92 : female : divorced/separated/married \n",
    "A93 : male : single \n",
    "A94 : male : married/widowed \n",
    "A95 : female : single \n",
    "\n",
    "* Attribute 10: (qualitative) \n",
    "Other debtors / guarantors \n",
    "A101 : none \n",
    "A102 : co-applicant \n",
    "A103 : guarantor \n",
    "\n",
    "* Attribute 11: (numerical) \n",
    "Present residence since \n",
    "\n",
    "* Attribute 12: (qualitative) \n",
    "Property \n",
    "A121 : real estate \n",
    "A122 : if not A121 : building society savings agreement/ life insurance \n",
    "A123 : if not A121/A122 : car or other, not in attribute 6 \n",
    "A124 : unknown / no property \n",
    "\n",
    "* Attribute 13: (numerical) \n",
    "Age in years \n",
    "\n",
    "* Attribute 14: (qualitative) \n",
    "Other installment plans \n",
    "A141 : bank \n",
    "A142 : stores \n",
    "A143 : none \n",
    "\n",
    "* Attribute 15: (qualitative) \n",
    "Housing \n",
    "A151 : rent \n",
    "A152 : own \n",
    "A153 : for free \n",
    "\n",
    "* Attribute 16: (numerical) \n",
    "Number of existing credits at this bank \n",
    "\n",
    "* Attribute 17: (qualitative) \n",
    "Job \n",
    "A171 : unemployed/ unskilled - non-resident \n",
    "A172 : unskilled - resident \n",
    "A173 : skilled employee / official \n",
    "A174 : management/ self-employed/ \n",
    "highly qualified employee/ officer \n",
    "\n",
    "* Attribute 18: (numerical) \n",
    "Number of people being liable to provide maintenance for \n",
    "\n",
    "* Attribute 19: (qualitative) \n",
    "Telephone \n",
    "A191 : none \n",
    "A192 : yes, registered under the customers name \n",
    "\n",
    "* Attribute 20: (qualitative) \n",
    "foreign worker \n",
    "A201 : yes \n",
    "A202 : no \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "creditX, creditY = load_svmlight_file(\"german\")\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "lr = LogisticRegression(C=1)\n",
    "scores_lr = cross_val_score(lr, creditX, creditY, cv=cv)\n",
    "print \"Logistic regression: \" + repr(scores_lr.mean())\n",
    "\n",
    "rbfSVM = svm.SVC(kernel='rbf', gamma=0.001, C=10)\n",
    "scores_rbf = cross_val_score(rbfSVM, creditX, creditY, cv=cv)\n",
    "print \"RBF SVM: \" + repr(scores_rbf.mean())\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "scores_dt = cross_val_score(dt, creditX, creditY, cv=cv)\n",
    "print \"Decision Tree: \" + repr(scores_dt.mean())\n",
    "\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=10),\n",
    "                         n_estimators=100,random_state=1)\n",
    "scores_bdt = cross_val_score(bdt, creditX, creditY, cv=cv)\n",
    "print \"Boosting Decision Trees: \" + repr(scores_bdt.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next dataset predicts forest cover type from GIS features: https://archive.ics.uci.edu/ml/datasets/Covertype\n",
    "\n",
    "We will use linear logistic regression, decision tree, and boosted decision tree.\n",
    "\n",
    "We are trying to distinguish lodgepole pine from other forest types (spruce/fir, Ponderosa pine, cottonwood/willow, aspen, Douglas-fir). The features are:\n",
    "\n",
    "* Elevation / quantitative /meters / Elevation in meters \n",
    "* Aspect / quantitative / azimuth / Aspect in degrees azimuth \n",
    "* Slope / quantitative / degrees / Slope in degrees \n",
    "* Horizontal_Distance_To_Hydrology / quantitative / meters / Horz Dist to nearest surface water features \n",
    "* Vertical_Distance_To_Hydrology / quantitative / meters / Vert Dist to nearest surface water features \n",
    "* Horizontal_Distance_To_Roadways / quantitative / meters / Horz Dist to nearest roadway \n",
    "* Hillshade_9am / quantitative / 0 to 255 index / Hillshade index at 9am, summer solstice \n",
    "* Hillshade_Noon / quantitative / 0 to 255 index / Hillshade index at noon, summer soltice \n",
    "* Hillshade_3pm / quantitative / 0 to 255 index / Hillshade index at 3pm, summer solstice \n",
    "* Horizontal_Distance_To_Fire_Points / quantitative / meters / Horz Dist to nearest wildfire ignition points \n",
    "* Wilderness_Area (4 binary columns) / qualitative / 0 (absence) or 1 (presence) / Wilderness area designation \n",
    "* Soil_Type (40 binary columns) / qualitative / 0 (absence) or 1 (presence) / Soil Type designation \n",
    "* Cover_Type (7 types) / integer / 1 to 7 / Forest Cover Type designation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "X, Y = load_svmlight_file(\"covertype\")\n",
    "\n",
    "cv = ShuffleSplit(n_splits=1, test_size=0.9, random_state=0)\n",
    "lr = LogisticRegression(C=1)\n",
    "scores_lr = cross_val_score(lr, X, Y, cv=cv)\n",
    "print \"Logistic regression: \" + repr(scores_lr.mean())\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "scores_dt = cross_val_score(dt, X, Y, cv=cv)\n",
    "print \"Decision Tree: \" + repr(scores_dt.mean())\n",
    "\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=30),\n",
    "                         n_estimators=10,random_state=1)\n",
    "scores_bdt = cross_val_score(bdt, X, Y, cv=cv)\n",
    "print \"Boosting Decision Trees: \" + repr(scores_bdt.mean())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
